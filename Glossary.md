# Glossary

### Prompt 
- The input text or instruction given to an AI model to generate a response.
- **Example:** "Write a poem about a robot who dreams of becoming a chef."

### Model
- The AI system that processes the prompt and generates output.

### Prompt Chaining
- Linking multiple prompts together to perform complex tasks or multi-step reasoning.

### Embedding
- Representing text as numerical vectors for tasks like semantic search or similarity comparison.

### System Prompt
- A hidden prompt that sets the behavior or personality of the model.

### Prompt Tuning / Fine-tuning
- Techniques to optimize prompts or train models on specific tasks using curated data.

### Large Language Model (LLM)
- A type of AI that can process and generate human-like text.
- **Example:** Open AI (ChatGPT), Google (Gemini, LaMDA, Bert), Meta (Llama), Antrophic (Claude), etc.

### Response | Completion
- The output generated by the LLM in response to a prompt.
- **Example:** "The robot whirred with excitement, its metal eyes sparkling. It imagined the sizzle of bacon, the aroma of freshly baked bread, and the laughter of happy customers."

### Top-p (Nucleus Sampling)
- Controls diversity by limiting the model to a subset of likely next words.

### Token
- A piece/unit of text (word or part of a word) that the LLM processes. Prompts and responses are made of tokens.

### Context
- The information (prompt + previous interactions) the model uses to generate a response.

### Context Window
- The maximum number of tokens the model can consider at once (prompt + response).

### Prompt Tuning
- Optimizing prompts for better performance without changing the model itself.

### Hallucination
- When the model generates false or misleading information confidently.

### Grounding
- Ensuring the model’s output is based on real, verifiable data or sources.

### Prompt Engineering Techniques

1. **Instruction Prompting:** 
- Giving clear instructions to guide the LLM’s behavior.
- **Example:** "Summarize the following text in a single sentence."

2. **Contextual Prompting:** 
- Provide relevant background information to guide the LLM's about the context.
- **Example:** "Write a story about a detective investigating a mysterious disappearance in a small town."

3. **Example Prompting:** 
- Offer examples of the desired output.
- **Example:** "Write a poem in the style of Edgar Allan Poe, similar to 'The Raven.'"

4. **Question Prompting:** 
- Ask a specific question to elicit a targeted response.
- **Example:** "What is the capital of France?"

5. **Role Prompting:** 
- Assigning a role to the LLM to influence its tone or style.
- **Example:** "You are a knowledgeable AI assistant. Answer the following question as if you were a historian."

6. **Zero-shot Prompting:**
- Asking the model to perform a task without providing examples.
- **Example:** “Translate this sentence into French: I love learning.”

7. **Few-shot Prompting:**
- Providing a few examples in the prompt to guide the model’s behavior.
- **Example:** Showing 2–3 translations before asking for a new one.

8. **Chain-of-Thought Prompting:**
- Encouraging the LLM to reason step-by-step before answering.
- Example: “Let’s think step by step...”


### **Temperature:** 
- A hyperparameter that controls the randomness of the LLM's output.
- Higher temperatures lead to more creative and diverse responses.
- Lower temperatures produce more focused and predictable outputs.
- **Example:** A temperature of 0.7 might produce a more creative response than a temperature of 0.2.

### Prompt Engineering Best Practices

1. **Clarity and Specificity:** 
- Ensure the prompt is clear, concise, and specific to avoid ambiguity.
- **Example:** Instead of "Write a story," try "Write a short story about a robot who falls in love with a human."

2. **Relevance and Context:** 
- Provide relevant context and information to guide the LLM's response.
- **Example:** If you want the LLM to write a poem about a specific event, provide details about the event.

3. **Iterative Refinement:** 
- Experiment with different prompts and refine them based on the LLM's responses.
- **Example:** If the LLM's response is not satisfactory, try rephrasing the prompt or providing more context.

4. **Bias Awareness:** 
- Be mindful of potential biases in the prompt and the LLM's responses.
- **Example:** Avoid prompts that perpetuate harmful stereotypes or biases.

5. **Ethical Considerations:** 
- Use prompt engineering responsibly and ethically.
- **Example:** Do not use LLMs to generate harmful or misleading content.          
